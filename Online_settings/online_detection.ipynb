{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "sNt9Ua2g8dCR",
    "outputId": "2ac0087d-88e1-4716-94d4-31520d7a4b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sk-video in c:\\users\\othmane\\anaconda3\\envs\\theano\\lib\\site-packages (1.1.10)\n",
      "Requirement already satisfied: numpy in c:\\users\\othmane\\anaconda3\\envs\\theano\\lib\\site-packages (from sk-video) (1.14.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\othmane\\anaconda3\\envs\\theano\\lib\\site-packages (from sk-video) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip  install sk-video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7oZnWo9ALYm_",
    "outputId": "9555b7ce-2a82-4370-c842-f16c7c654e4a"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers import Input, Conv3D, MaxPooling3D, Dense, Flatten, ZeroPadding3D, Dropout, Subtract, BatchNormalization\n",
    "import skvideo.io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tPIV-Ksfh2Zr"
   },
   "source": [
    "# Base Model\n",
    "\n",
    "Our base model consists of 3D ConvNets from Conv1 to Pool5 and 3 fully connected layers (FC6, FC7, FC8)which has been pre-trained on Sports-1M. We delete the FC8 from our model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SjedvEE6LYnF"
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = 'https://github.com/adamcasson/c3d/releases/download/v0.1/sports1M_weights_tf.h5'\n",
    "C3D_MEAN_PATH = 'https://github.com/adamcasson/c3d/releases/download/v0.1/c3d_mean.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n0IbdEdZZAJZ"
   },
   "outputs": [],
   "source": [
    "def base_model():\n",
    "\n",
    "    if K.image_data_format() == 'channels_last':    \n",
    "        shape0 = (16,112,112,3)    \n",
    "    else:   \n",
    "        shape0 = (3,16,112,112)\n",
    "\n",
    "    model_base = Sequential()\n",
    "    \n",
    "    model_base.add(Conv3D(64, 3, activation='relu', padding='same', name='conv1', input_shape=shape0))\n",
    "    model_base.add(MaxPooling3D(pool_size=(1,2,2), strides=(1,2,2), padding='same', name='pool1'))\n",
    "    \n",
    "    model_base.add(Conv3D(128, 3, activation='relu', padding='same', name='conv2'))\n",
    "    model_base.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), padding='valid', name='pool2'))\n",
    "    \n",
    "    model_base.add(Conv3D(256, 3, activation='relu', padding='same', name='conv3a'))\n",
    "    model_base.add(Conv3D(256, 3, activation='relu', padding='same', name='conv3b'))\n",
    "    model_base.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), padding='valid', name='pool3'))\n",
    "    \n",
    "    model_base.add(Conv3D(512, 3, activation='relu', padding='same', name='conv4a'))\n",
    "    model_base.add(Conv3D(512, 3, activation='relu', padding='same', name='conv4b'))\n",
    "    model_base.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), padding='valid', name='pool4'))\n",
    "    \n",
    "    model_base.add(Conv3D(512, 3, activation='relu', padding='same', name='conv5a'))\n",
    "    model_base.add(Conv3D(512, 3, activation='relu', padding='same', name='conv5b'))\n",
    "    model_base.add(ZeroPadding3D(padding=(0,1,1)))\n",
    "    model_base.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), padding='valid', name='pool5'))\n",
    "    \n",
    "    model_base.add(Flatten())\n",
    "    \n",
    "    model_base.add(Dense(4096, activation='relu', name='fc6', input_shape = (None, 8192)))\n",
    "    model_base.add(Dropout(0.5))\n",
    "    model_base.add(Dense(4096, activation='relu', name='fc7'))\n",
    "    model_base.add(Dropout(0.5))\n",
    "    model_base.add(Dense(487, activation='softmax', name='fc8'))\n",
    "\n",
    "    weights_path = get_file('sports1M_weights_tf.h5',\n",
    "                         WEIGHTS_PATH,\n",
    "                         cache_subdir='models',\n",
    "                         md5_hash='b7a93b2f9156ccbebe3ca24b41fc5402')\n",
    "        \n",
    "    model_base.load_weights(weights_path)\n",
    "\n",
    "    model_base.pop()\n",
    "    \n",
    "    return model_base\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6r0t6tKxjtD_"
   },
   "source": [
    "# Model the Temporal Consistency\n",
    "\n",
    "We add a clasification layer FC8 to our model, that gives the class of the actual window (background or action). We also add a second loss to our model, that mesures the difference between the FC7 layer for the actual window and the next window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "ErFTGOPbbTN7",
    "outputId": "0b8fe1bb-dc9b-4584-e65b-92219302b326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "start_window (InputLayer)       (None, 16, 112, 112, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4096)         77995776    start_window[0][0]               \n",
      "                                                                 followup_window[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "followup_window (InputLayer)    (None, 16, 112, 112, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 4096)         0           sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc8 (Dense)                     (None, 2)            8194        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "out (Subtract)                  (None, 4096)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 78,003,970\n",
      "Trainable params: 78,003,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_base = base_model()\n",
    "\n",
    "if K.image_data_format() == 'channels_last':    \n",
    "    shape0 = (16,112,112,3)    \n",
    "else:   \n",
    "    shape0 = (3,16,112,112)\n",
    "\n",
    "start_window = Input(shape=shape0, dtype='float32', name='start_window')\n",
    "followup_window = Input(shape=shape0, dtype='float32', name='followup_window')\n",
    "\n",
    "fc7 =model_base(start_window)\n",
    "\n",
    "drop2 = Dropout(0.5)(fc7)\n",
    "fc8 = Dense(2, activation='sigmoid', name='fc8')(drop2)\n",
    "\n",
    "\n",
    "out1 = fc7\n",
    "out2 = model_base(followup_window)\n",
    "\n",
    "out = Subtract(name='out')([out1, out2])\n",
    "\n",
    "model_1 = Model([start_window,followup_window],[fc8,out])\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wcw9IpFpg2VK"
   },
   "outputs": [],
   "source": [
    "def loss_classification(y_true, y_pred):\n",
    "    return -K.mean(K.log(K.dot(y_pred,K.transpose(y_true))), axis=-1)\n",
    "    \n",
    "def loss_temporal_consistency(y_true,y_pred):\n",
    "    return K.mean(K.square(K.dot(out,K.transpose(y_true))), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aGm0m4eLg_mS"
   },
   "outputs": [],
   "source": [
    "model_1.compile(optimizer='adam',\n",
    "              loss={'fc8': loss_classification, 'out': loss_temporal_consistency},\n",
    "              loss_weights={'fc8': 1., 'out': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gLMSr679krzu"
   },
   "source": [
    "# Training phase 1 \n",
    "We train our model_1 by minimizing $\\mathcal{L}_{classification} + \\lambda\\mathcal{L}_{similarity}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "3_sja5gW9Ir0",
    "outputId": "56303dff-e09d-456a-9f77-6d6bfe6ace32"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "path1 = 'D:/workspace/MVA/ORCV/Final_Project/Data_Sets/UCF-Anomaly-Detection-Dataset/UCF_Crimes/Videos/Normal/Training_Normal_Videos_Anomaly/Normal_Videos001_x264.mp4'\n",
    "path2 = 'D:/workspace/MVA/ORCV/Final_Project/Data_Sets/UCF-Anomaly-Detection-Dataset/UCF_Crimes/Videos/Abnormal/Abuse/Abuse001_x264.mp4'\n",
    "\n",
    "\n",
    "Normal_Video = skvideo.io.vread(path1,\n",
    "                          outputdict={\n",
    "                            \"-sws_flags\": \"bilinear\",\n",
    "                            \"-s\": \"112x112\"\n",
    "                          })\n",
    "\n",
    "Abnormal_Video = skvideo.io.vread(path2,\n",
    "                          outputdict={\n",
    "                            \"-sws_flags\": \"bilinear\",\n",
    "                            \"-s\": \"112x112\"\n",
    "                          })\n",
    "\n",
    "action_intervals = [[230, 365], [-1,-1]]\n",
    "\n",
    "Videos = [Normal_Video, Abnormal_Video]\n",
    "\n",
    "\n",
    "# Let's train the model on two videos (Extansion well be easy)\n",
    "# We do just on training iteration, in which we create one batch containing Nb_training_examples = Nb_abnormal*15\n",
    "\n",
    "print(\"Constructing Postive Exapmles\")\n",
    "positive_indexes = []\n",
    "\n",
    "count = -1\n",
    "for action in range(len(action_intervals)):\n",
    "  positive_indexes.append([])\n",
    "  start = action_intervals[action][0]\n",
    "  idx = 0\n",
    "  while (start!=-1) and (idx < len(action_intervals[action])):\n",
    "    start = action_intervals[action][idx]\n",
    "    idx += 2\n",
    "    positive_indexes[action] = positive_indexes[action]+([start-15+i for i in range(15)])\n",
    "    \n",
    "    for i in range(15):\n",
    "      count += 1\n",
    "      if(count==0):\n",
    "        actuals = np.expand_dims(Videos[action][start-15+i:start+i+1], axis=0)\n",
    "        nexts = np.expand_dims(Videos[action][start+i+1:start+i+17], axis=0)\n",
    "      if(count>0):\n",
    "        actuals = np.vstack((actuals, np.expand_dims(Videos[action][start-15+i:start+i+1], axis=0)))\n",
    "        nexts   = np.vstack((nexts, np.expand_dims(Videos[action][start+i+1:start+i+17], axis=0)))\n",
    "\n",
    "nbr_positive = actuals.shape[0]\n",
    "print(\"Constructing Negativve Exapmles\")\n",
    "\n",
    "nbr_neg = 0 # nbr of negative examples selected \n",
    "while (nbr_neg<nbr_positive):\n",
    "  video_indx = random.randint(0,len(Videos)-1) #Pick randomly a video \n",
    "  start_frame = random.randint(0,Videos[video_indx].shape[0]-33)\n",
    "  \n",
    "  while (start_frame in positive_indexes[video_indx]):\n",
    "    start_frame = random.randint(0,Videos[video_indx].shape[0]-33) #pick a new sequence till it is abnormal\n",
    "  nbr_neg = nbr_neg + 1\n",
    "  \n",
    "  actuals = np.vstack((actuals, np.expand_dims(Videos[video_indx][start_frame:start_frame+16], axis=0)))\n",
    "  nexts   = np.vstack((nexts, np.expand_dims(Videos[video_indx][start_frame+16:start_frame+32], axis=0)))\n",
    "  \n",
    "inputs = [actuals, nexts]\n",
    "labels = np.zeros((nbr_positive+nbr_neg,1))\n",
    "labels[0:nbr_positive,:] += 1 \n",
    "\n",
    "labels_1 = labels\n",
    "\n",
    "labels = np.zeros((nbr_positive+nbr_neg,4096))\n",
    "labels[0:nbr_positive,:] += 1\n",
    "\n",
    "labels_2 = labels\n",
    "\n",
    "labels = [labels_1, labels_2]\n",
    "\n",
    "\n",
    "print(\"Start Training\")\n",
    "loss = model_1.train_on_batch(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rUbmWmpBPx5I"
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Z9S5XCYmYP1"
   },
   "source": [
    "# Generate Hard Negative Samples via GAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator \n",
    "\n",
    "The generator takes as input a 100-dimensional noise, It is composed of two fully-connected layers of 8192 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 8192)              67117056  \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8192)              32768     \n",
      "=================================================================\n",
      "Total params: 68,009,984\n",
      "Trainable params: 67,977,216\n",
      "Non-trainable params: 32,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = Sequential()\n",
    "\n",
    "generator.add(Dense(8192, activation='relu', name='fc1',input_shape=(100,)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Dense(8192, activation='relu', name='fc2'))\n",
    "generator.add(BatchNormalization())\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Block and FC6+FC7 block\n",
    "\n",
    "We create a block model containing all the covolutional layers of the base_model till pool5, And we get a modedl composed of layers fc6 and fc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 16, 112, 112, 64)  5248      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 16, 56, 56, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 16, 56, 56, 128)   221312    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 8, 28, 28, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 8, 28, 28, 256)    884992    \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 8, 28, 28, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 4, 14, 14, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 4, 14, 14, 512)    3539456   \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 4, 14, 14, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "zero_padding3d_1 (ZeroPaddin (None, 2, 9, 9, 512)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "=================================================================\n",
      "Total params: 27,655,936\n",
      "Trainable params: 27,655,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc6 (Dense)                  multiple                  33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  multiple                  16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 50,339,840\n",
      "Trainable params: 50,339,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model = Sequential()\n",
    "fc6_fc7_model = Sequential()\n",
    "\n",
    "index = 0 # 0 to add layers in conv_model, and \n",
    "for layer in model_1.get_layer(index=1).layers:\n",
    "    if(index == 0):\n",
    "        conv_model.add(layer)\n",
    "    if(index == 1):\n",
    "        fc6_fc7_model.add(layer)\n",
    "        \n",
    "    if(layer.name == 'flatten_1'):\n",
    "        index = 1\n",
    "        \n",
    "print(conv_model.summary())\n",
    "\n",
    "print(fc6_fc7_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriminator \n",
    "\n",
    "We use the blocks that we have created to create the Descriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(8192)])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_last':    \n",
    "    shape0 = (16,112,112,3)    \n",
    "else:   \n",
    "    shape0 = (3,16,112,112)\n",
    "\n",
    "actual_window = Input(shape=shape0, dtype='float32', name='actual_window')\n",
    "next_window = Input(shape=shape0, dtype='float32', name='next_window')\n",
    "noise = Input(shape=(None,100), dtype='float32', name='noise')\n",
    "\n",
    "generated_sample = generator(noise)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "c3d.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
